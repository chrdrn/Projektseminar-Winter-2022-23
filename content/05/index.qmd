---
title: "Projektseminar"
subtitle: "Datenaufbereitung IV & Annahmen"
title-slide-attributes:
  data-background-image: ../../images/background_dark_red.svg
  data-background-size: cover
  data-background-opacity: ".5"
  data-background-color: "#041E42"
author: 
  - name: Julius Klingelhoefer 
    url: https://twitter.com/klingelhoefer_j/
    affiliation: Juniorprofessur f√ºr Kommunikationswissenschaft
    affiliation-url: https://www.kommunikationswissenschaft.rw.fau.de/julius-klingelhoefer/
date: "`r Sys.Date()`" 
#date-format: "DD.MM.YYYY"
format:
  revealjs:
    include-in-header: ../eventlistener.html
    width: 1920
    height: 1080
    menu: false
    toc: true
    toc-depth: 1
    toc-title: "Inhalt"
    auto-animate-duration: 0.5
    auto-animate-easing: ease-in-out
    transition: slide
    background-transition: fade
    transition-speed: fast
    theme: ../slidetheme.scss
    fontsize: 5em
    #template-partials:
    slide-number: c
    chalkboard:
      buttons: false
      theme: whiteboard
    preview-links: auto
    logo: ../../images/logo.svg
    #footer: "[Projektseminar 22/23](https://github.com/klingelhoefer/Projektseminar-Winter-2022-23)"
comments:
  hypothesis: 
    theme: clean
execute:
  echo: true
filters: 
  - ../bg_style.lua
bibliography: references.bib
csl: ../apa.csl
editor_options: 
  chunk_output_type: console
---

# Erhebungs-Updates

![](https://cdn.vox-cdn.com/thumbor/6WUQ-FozHdnzwKN7t31bJWPbdxI=/0x0:900x500/1400x1050/filters:focal(450x250:451x251)/cdn.vox-cdn.com/uploads/chorus_asset/file/6438793/this-is-fine.jpg){fig-align="center" width="933"}

```{r}
#| echo: false
#| output: FALSE

base::ifelse(file.exists("compliance_overview.R"),
             source(file = "compliance_overview.R"),
             source(file = "../../compliance_overview.R"))
```

## Compliance I {auto-animate="T"}

```{r}
#| fig.height: 6
#| fig.width: 20
ggplotly(daily_plot)
```

Stand `r paste(Sys.time())`

## Compliance II {auto-animate="T"}

```{r}
#| echo: false
#| fig.height: 30
#| fig.width: 20
ggplotly(fillout_plot)
```

Stand `r paste(Sys.time())`

## Von Ihnen #2

-   Wie lief es bei der Rekrutierung?

-   Welche Ma√ünahmen haben Sie durchgef√ºhrt und welche waren erfolgreich?

# Throwback zur letzten Woche

## Live-Coding-Session

üíª

```{=html}
<!--# F√ºhren Sie Analysen zur Compliance durch

1.  Finden Sie heraus, wie hoch die durchschnittliche Compliance ist. Dabei z√§hlen nur Situations- und Tagesabschlussfrageb√∂gen

2.  Stellen Sie die Compliance tabellarisch und/oder grafisch dar 

3.  Identifizieren Sie Personen, die die Vorbefragung m√∂glicherweise unaufmerksam ausgef√ºllt haben, da sie zu schnell waren (`time_rsi`)

4.  Optionale Bonusaufgabe: Treffen Sie eine Vorhersage dar√ºber, wie viele Personen a) die mindest-compliance f√ºr die Belohnung erreichen weden und b) eine compliance von \>= .75 erreichen -->
```
## Gemeinsame Besprechung der Compliance-Berechnung

```{r}
# We can use the following variables I have already calculated (see Git):
#   - max_participation = Maximum number of probes that a participant can fill ou
#     (note this is based on the da)
#   - valid_probe = Tells us how many probes a participant filled out
#   - day_newest = most recent date a participant filled anything out

expected_compliance = dl %>% 
  group_by(id) %>% 
  summarise(
    valid_probe = sum(valid_probe),
    max_participation = mean(max_participation) ,
    attr = .9, #let's assume attrition of 10% and that this stays constant
    day_newest = max(day_newest),
    max_day_newest = max(dl$day_newest, na.rm = T),
    duration_end = mean(duration_end, na.rm =T)
    ) %>% 
  mutate(
    compliance = valid_probe/max_participation
  ) %>%
summarise(
    pred_compl = 
      ifelse(
        duration_end <= Sys.Date(),
        compliance,
        ifelse(
          max_day_newest == day_newest,
          compliance * attr,  
          # let's assume dropout if no probe on most recent day
          NA)
        )
  )
    
# hist(expected_compliance$pred_compl) # uncomment to get histogram 

table(expected_compliance$pred_compl > .6)
table(expected_compliance$pred_compl > .75)
```

# Mehrebenenanalyse: Refresher

## Back to the Basics

-   In der Realit√§t (fast) √ºberall komplexe **hierarchische Strukturen**:

    -   (L1 geschachtelt in L2)

-   Vernachl√§ssigung von Mehrebenenstruktur kann falsche Aussagen produzieren

-   Mehrebenenalyse

    -   Kontrolliert und modelliert Abh√§ngigkeit

    -   Erm√∂glicht die Untersuchung des **Zusammenwirkens verschiedener Ebenen**

-   Mehrebenenmodelle: konzeptionelle Erweiterung der (linearen) Regression:

    -   statt OLS: (Restricted) Maximum Likehood-Sch√§tzung

    -   Gro√üteil der Annahmen gleich wie OLS-Regression

## √úberpr√ºfung der Annahmen

```{r}
#| echo: false

dl = dl %>% 
  rowwise() %>% 
  mutate(
    disco_i = mean(c_across(disco_1:disco_5), na.rm = T),
    motivation_i = mean(c_across(motivation_distraction:motivation_social), na.rm = T),
    .before = "probe_time"
  ) %>% 
  ungroup()


```

Mit dem `performance`-Package[^1]:

[^1]: Achtung: Die Beispieldaten sind noch nicht bereinigt

√úbersicht √ºber alle Tests:

```{r}
#|eval: false
m0_disco = dl %>% lmer(disco_i ~ 1 + (1 | id), data = ., REML = FALSE)
plot_check = m0_disco %>% performance::check_model()
```

## Linearit√§t

::: columns
::: {.column width="50%"}
```{r}
diagnostics = m0_disco %>% 
  performance::check_model()

lin = diagnostics$NCV %>%
  ggplot(aes(x, y)) +
  geom_point() +
  geom_abline(
    slope = 0, intercept = 0, linetype = "dashed",
    color = "red"
  ) +
  geom_smooth() +
  labs(
    x = "Fitted values", y = "Residuals",
    title = "Linearity"
  ) +
  theme_pubr()

```
:::

::: {.column width="50%"}
```{r}
#| echo: false
lin
```
:::
:::

## Normalverteilung der Residuen

```{r}
plot(performance::check_normality(x = m0_disco, type = "qq"))
```

## Heteroskedastizit√§t

```{r}
plot(performance::check_heteroscedasticity(m0_disco))
```

## Outlier

```{r}
m0_disco %>% performance::check_outliers() %>% plot()
```

# Fragen?

<!-- ## Varying slopes & intercepts -->

<!-- ![](images/paste-3B876F60.png){fig-align="center"} -->

<!-- Quelle: [@gelman2007, p. 238] -->

<!-- ## Random Effects Within-Between Modell (REWB) {auto-animate="T"} -->

<!-- ![Rube Waddell (¬© Public Domain)](images/paste-16ED8EC1.png){fig-align="center"} -->

<!-- ## REWB: Grundidee {auto-animate="T"} -->

<!-- -   Mit Hilfe des REWB-Modells lassen sich f√ºr jede L1-Variable zwei Effekte sch√§tzen: -->

<!--     -   L1-Variable am Personenmittelwert zentriert: **within-person Effekt** -->

<!--     -   L2-Personenmittelwert der L1-Variable: **between-person Effekt** -->

<!-- -   Zus√§tzlich: -->

<!--     -   weitere L1- und L2-Pr√§diktoren und -->

<!--     -   varying slopes von L1-Pr√§diktoren m√∂glich -->

<!-- -    -->

# Arbeitsauftrag

1.  Suchen Sie sich eine f√ºr Ihre Analysen zentrale abh√§ngige Variable heraus
2.  Betrachten Sie die Verteilung der Variablen und die Annahmen anhand des Nullmodells
3.  √úberpr√ºfen und Interpretieren Sie graphisch die Annahmen
4.  Bitte rechnen Sie noch **keine Modelle mit Pr√§diktoren, bis die Erhebung abgeschlossen ist**
