---
title: "Projektseminar"
subtitle: "Datenaufbereitung I"
title-slide-attributes:
  data-background-image: ../../images/background_dark_red.svg
  data-background-size: cover
  data-background-opacity: ".5"
  data-background-color: "#041E42"
author: 
  - name: Julius Klingelhoefer 
    url: https://twitter.com/klingelhoefer_j/
    affiliation: Juniorprofessur f√ºr Kommunikationswissenschaft
    affiliation-url: https://www.kommunikationswissenschaft.rw.fau.de/julius-klingelhoefer/
date: "`r Sys.Date()`" 
#date-format: "DD.MM.YYYY"
format:
  revealjs:
    include-in-header: ../eventlistener.html
    width: 1920
    height: 1080
    menu: false
    toc: true
    toc-depth: 1
    toc-title: "Inhalt"
    auto-animate-duration: 0.5
    auto-animate-easing: ease-in-out
    transition: slide
    background-transition: fade
    transition-speed: fast
    theme: ../slidetheme.scss
    fontsize: 5em
    #template-partials:
    slide-number: c
    chalkboard:
      buttons: false
      theme: whiteboard
    preview-links: auto
    logo: ../../images/logo.svg
    #footer: "[Projektseminar 22/23](https://github.com/klingelhoefer/Projektseminar-Winter-2022-23)"
comments:
  hypothesis: 
    theme: clean
execute:
  echo: true
filters: 
  - ../bg_style.lua
bibliography: references.bib
csl: ../apa.csl
editor_options: 
  chunk_output_type: console
---

# Housekeeping

**üßπ**

```{r setup}
#| echo: false
#| output: false


# installing and activating required packages 
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, dplyr, janitor, renv, readxl, haven, visdat, naniar, dplyr, ggpubr)


#_______________________
# The following lines include code from another markdown document that are pasted here without explanations. See the pretest data cleaning and joining script for full context (not in this github repository) 
#_______________________

# Importing data from the version without logging
d_log_f = read_excel("../../pretest/data/Momentary_Disco!+NO+LOGGING_20221020T113348+0200.xlsx")
# creating unique IDs (to avoid conflicts with the other study version)
d_log_f = d_log_f %>% 
  mutate(id = paste0("nl_",Participant)) %>% 
  mutate(version = "no_logging") %>% 
  select(id, version, everything())


# Importing data from the version with logging
d_log_t = read_excel("../../pretest/data/momentary_disco_WITH_logging_20221020T113642+0200.xlsx")
# creating unique IDs (to avoid conflicts with the other study version)
d_log_t = d_log_t %>% 
  mutate(id = paste0("yl_",Participant)) %>%
  mutate(version = "with_logging") %>% 
  select(id, version, everything())


# Joining both datasets
data = rbind(d_log_f, d_log_t)
rm(d_log_f, d_log_t) # removing seperate dataframe, only keeping joined df


# Merging variables present in the 4 daily and the one end of day questionnaire
# moving variable names with _1 to the correct names
x = data %>% 
  filter(Form == "b End of Day") %>% 
  mutate(
    wb_ge = wb_ge_1,
    wb_energy = wb_energy_1,
    wb_stress = wb_stress_1,
    wb_connect = wb_connect_1,
    procra = procra_1,
    screentime_work = screentime_work_1,
    screentime_leisure = screentime_leisure_1,
    disco_1 = disco_1_1, 
    disco_2 = disco_1_2,
    disco_3 = disco_1_3,
    disco_4 = disco_1_4,
    disco_5 = disco_1_5,
    disco_6 = disco_1_6,
    disco_sd = disco_sd_1,
    motivation_distraction = motivation_distraction_1,
    motivation_wellbeing = motivation_wellbeing_1,
    motivation_social = motivation_social_1,
    goal_conf_disconnection = goal_conf_disconnection_1,
    ns_autonomy = ns_autonomy_1,
    ns_competence = ns_competence_1,
    ns_relatedness = ns_relatedness_1,
    disco_desire = disco_desire_1,
    media_category_1 = media_category_1_1,
    media_category_2 = media_category_1_2,
    media_category_3 = media_category_1_3,
    media_category_4 = media_category_1_4,
    media_category_5 = media_category_1_5,
    media_category_6 = media_category_1_6,
    media_category_6 = media_category_1_6,
    media_category_7 = media_category_1_7,
  )

# filtering out all non-end of day questionnaires
y = data %>% filter(Form != "b End of Day")

# merging both filtered sets, selecting only forms with variables relevant for the analyses
data = rbind(x, y)
data = data %>%
  arrange(Trigger_time) %>% 
  arrange(id) %>% 
  filter(Participant >= 10) %>%  
  # IDs 1-10 were reserved for technical pretests in both versions
  filter(Form == "a Situational Survey" | Form == "b End of Day" | Form == "c Final Survey")  

# dropping variables that only contain text or non-recorded values
na_vars = data %>%
  summarise_all(funs(sum(is.na(.)))) 
all_na_list = NULL
for (i in 1:ncol(data))
{
  if(na_vars[1,i] == nrow(data))
  {
  all_na_list = append(all_na_list, colnames(na_vars[i]))
  print(i)
  }
}
all_na_list

# creating a vector with all unwanted variables (e.g. movisensXS creates a variable each time more than one question question is shown per page and for every text displayed, including instructions; also removing the duplicate variables for the end of day survey that were moved to the correctly named variables earlier)
unwanted_vars = c("wb_ge_1", "wb_energy_1", "wb_stress_1", "wb_connect_1", "procra_1", "screentime_work_1", "screentime_leisure_1", "disco_1_1", "disco_1_2", "disco_1_3", "disco_1_4", "disco_1_5", "disco_1_6", "disco_sd_1", "motivation_distraction_1", "motivation_wellbeing_1", "motivation_social_1", "goal_conf_disconnection_1", "ns_autonomy_1", "ns_competence_1", "ns_relatedness_1", "disco_desire_1", "media_category_1_1", "media_category_1_2", "media_category_1_3", "media_category_1_4", "media_category_1_5", "media_category_1_6", "media_category_1_6", "media_category_1_7", "text_0", "blank_1", "text_1", "text_2", "item_863", "item_607", "item_895", "text_3", "item_1403", "text_6", "item_902", "item_910", "item_969", "item_1057", "item_986", "item_1114", "item_1114_copy1233", "item_1114_copy1233_copy1413", "item_1478", "item_738", "item_1383", "item_753", "item_798", "item_938_copy1728", "item_1151", "item_841_copy852", "item_841", "item_1642", "item_551", "item_1519_copy1527", "item_1519","item_1366", "item_1381", "item_662", "item_670", "item_730", "item_476", "item_484", "item_646", "item_1019", "item_617", "item_633", "item_638", "item_708", "welcome_text", "welcome_text_copy527", "welcome_text_copy527_copy735", "item_1427", "item_1432", "welcome_text_copy521", "welcome_text_copy515", "item_673", "item_848_copy856", "item_848", "item_868", "item_879", "item_673_copy887", "feedback_copy896", "item_916", "item_916_copy931", "item_1443", "item_656", "item_792", "item_810", "item_820", "item_820_copy760", "item985", "item_768", "item39424")
print(unwanted_vars)

# filtering out the list of unwanted variables
data_filtered = data %>% 
  select(!one_of(unwanted_vars))

#renaming inappropriately named variables
data_filtered = data_filtered %>% 
  rename(
    motivation_distraction_day = motivation_distraction_day_copy1729,
    motivation_wellbeing_day = motivation_wellbeing_day_copy1730,
    motivation_social_day = motivation_social_day_copy1731,
  )

# renaming disco_6 to reflect that this item is selected if disco occurred
data_filtered = data_filtered %>% 
  rename(
    no_disco = disco_6 
  )

# setting filtered data to data
data = data_filtered
print(colnames(data))

# removing no longer needed variables/data frames
rm(data_filtered, na_vars, x, y, all_na_list, i, unwanted_vars)


sosci_pre_survey = read_excel("../../pretest/data/data_abschalten_2022-10-20_18-11.xlsx", col_types = "guess")

#converting one double to string
sosci_pre_survey = sosci_pre_survey %>% mutate(FI04_01 = toString(FI04_01))

# note: 9 needs to be added because 1-9 were reserved for the technical pretest
# adding 9 for both
sosci_pre_survey = sosci_pre_survey %>% 
  mutate(
    movi_id_nl = UR01+9, #1 in the urn corresponds to id no. 10
    movi_id_yl = UR02+9  #1 in the urn corresponds to id no. 10
  ) %>% 
  select(movi_id_nl, movi_id_yl, everything())

#creating id variable for non-logging version
sosci_pre_survey_nl = sosci_pre_survey %>% 
  filter(!is.na(movi_id_nl)) %>% 
  mutate(id = paste0("nl_", movi_id_nl)) %>%
  select(id, everything())

#creating id variable for logging version
sosci_pre_survey_yl = sosci_pre_survey %>% 
  filter(!is.na(movi_id_yl)) %>% 
  mutate(id = paste0("yl_", movi_id_yl)) %>%
  select(id, everything())

sosci_pre_survey = rbind(sosci_pre_survey_nl, sosci_pre_survey_yl) #joining both versions
rm(sosci_pre_survey_nl, sosci_pre_survey_yl) # removing temporary data frames

data_long = merge(data, sosci_pre_survey, by = "id")


data_long = data_long %>%
  clean_names
```

## Neuerungen

-   Mehr Abwechslung und Interaktivit√§t: R-√úbungselemte schon in den Vortrag:

    -   Kleinere Arbeitsphasen w√§hrend des Vortrags

    -   √úberarbeitungen aus der Sitzung sind Grundlage f√ºr die anschlie√üenden Arbeitsauftr√§ge

-   Pr√§-Registrierung(en): Jetzt verf√ºgbar, s. [Teams]{.purple}!

## RStudio Server

-   Weiterhin Nutzung des RStudio Servers m√∂glich (au√üer Mittwochs) Erreichbar unter: [http://131.188.248.179:8787](http://131.188.248.179:8787)

-   **nur via VPN** erreichbar

-   Bitte nutzen Sie Ihren (alten) pers√∂nlichen Login

## Sharepics

- Start der Erhebung am 14.11.

- F√ºr uns ebenfalls?

# Datenaufbereitung

Von Rohdaten bis zur Analyse

import ‚û°Ô∏è tidy ‚û°Ô∏è transform ‚û°Ô∏è repeat

## Prozess der Datenaufbereitung

::: columns
::: {.column width="50%"}
Die **Aufbereitung** nimmt in der Regel den Gro√üteil der Zeit in Anspruch

H√§ufig mehrfache **Wiederholung** dreier Schritte:

-   (explorative) **Erkundung**

-   **Standardisierung**

-   (erneute) **Bereinung** der Daten
:::

::: {.column width="50%"}
### Typische Pipeline:

![](https://d33wubrfki0l68.cloudfront.net/795c039ba2520455d833b4034befc8cf360a70ba/558a5/diagrams/data-science-explore.png){width="100%"}

@wickham2016
:::
:::

# Datenstruktur(en)

Zusammenf√ºgen von Datens√§tzen

import ‚ûï bind ‚ûï join ‚ûï merge

## St√§rke von R: Umgang mit Daten

-   Ein Bereich, in dem R wirklich gl√§nzt, ist die F√§higkeit mit mehreren und verschiedenen Datenquellen (gleichzeitig) zu arbeiten

-   R verf√ºgt √ºber eine Reihe an Paketen f√ºr den Import, die Transformation sowie die Bearbeitung verschiedenster Datenquellen

## Datenimport in R {auto-animate="true"}

Einer der ersten Arbeitschritte ist der Import externer Daten in R. Daf√ºr gibt es neben der Base R-Funktionen eine Vielzahl an verschiedenen Paketen:

-   `haven` - SPSS, Stata, and SAS files

-   `DBI` - databases

-   `jsonlite` - json

-   `xml2` - XML

-   `httr` - Web APIs

-   `rvest` - HTML (Web Scraping)

-   `readr::read_lines()` - text data

-   ...

## Datenimport in R {auto-animate="T"}

-   ...

**Grunds√§tzlich gilt**

-   Je "einfacher" die Formatierung der Daten, desto weniger komplex ist der Import.

-   Import von Textdatein (`.csv`) i.d.R. einfacher und ohne gr√∂√üere Komplikationen.

-   Andere Dateienformate (`.sav`) k√∂nnen Vorz√ºge haben (z.B. Variable- und Value Labels), die den potentiellen Mehraufwand beim Import rechtfertigen.

## Arten der Zusammenf√ºhrung

-   Drei grunds√§tzliche M√∂glichkeiten, Datens√§tze zu verbinden:

    <div>

    -   Addition zus√§tzlicher **Variablen** f√ºr bestehende F√§lle

    -   Addition zus√§tzlicher **F√§lle** f√ºr bestehende Variablen

    -   Addition zu√§tzlicher **Variablen & F√§lle**

    </div>

F√ºr alle M√∂glichkeiten gibt es sowohl simple (z.B. durch die `bind_`-Funktionen), aber auch komplexere L√∂sungen (z.B. die `_join`-Funktionen)[^1].

[^1]: Quelle der folgenden Unterabschnitte: @positsoftware2021, dplyr cheat sheet, CC BY SA

## `bind_cols()` {auto-animate="T"}

::: columns
::: {.column width="auto"}
x

[A]{.square_darkgrey data-id="box_1"} [B]{.square_darkgrey data-id="box_2"} [C]{.square_darkgrey data-id="box_3"}

[a]{.square_lightgrey data-id="box_4"} [t]{.square_lightgrey data-id="box_5"} [1]{.square_lightgrey data-id="box_6"}

[b]{.square_lightgrey data-id="box_7"} [u]{.square_lightgrey data-id="box_8"} [2]{.square_lightgrey data-id="box_9"}

[c]{.square_lightgrey data-id="box_10"} [v]{.square_lightgrey data-id="box_11"} [3]{.square_lightgrey data-id="box_12"}
:::

::: {.column width="40%"}
:::

::: {.column width="auto"}
y

[E]{.square_darkblue data-id="box_13"} [F]{.square_darkblue data-id="box_14"} [G]{.square_darkblue data-id="box_15"}

[a]{.square_lightblue data-id="box_16"} [t]{.square_lightblue data-id="box_17"} [3]{.square_lightblue data-id="box_18"}

[b]{.square_lightblue data-id="box_19"} [u]{.square_lightblue data-id="box_20"} [2]{.square_lightblue data-id="box_21"}

[d]{.square_lightblue data-id="box_22"} [w]{.square_lightblue data-id="box_23"} [1]{.square_lightblue data-id="box_24"}
:::
:::

## `bind_cols()` {auto-animate="T"}

::: columns
::: {.column width="auto"}
x & y

[A]{.square_darkgrey data-id="box_1"} [B]{.square_darkgrey data-id="box_2"} [C]{.square_darkgrey data-id="box_3"} [E]{.square_darkblue data-id="box_13"} [F]{.square_darkblue data-id="box_14"} [G]{.square_darkblue data-id="box_15"}

[a]{.square_lightgrey data-id="box_4"} [t]{.square_lightgrey data-id="box_5"} [1]{.square_lightgrey data-id="box_6"} [a]{.square_lightblue data-id="box_16"} [t]{.square_lightblue data-id="box_17"} [3]{.square_lightblue data-id="box_18"}

[b]{.square_lightgrey data-id="box_7"} [u]{.square_lightgrey data-id="box_8"} [2]{.square_lightgrey data-id="box_9"} [b]{.square_lightblue data-id="box_19"} [u]{.square_lightblue data-id="box_20"} [2]{.square_lightblue data-id="box_21"}

[c]{.square_lightgrey data-id="box_10"} [v]{.square_lightgrey data-id="box_11"} [3]{.square_lightgrey data-id="box_12"} [d]{.square_lightblue data-id="box_22"} [w]{.square_lightblue data-id="box_23"} [1]{.square_lightblue data-id="box_24"}
:::
:::

-   **Um Variablen zu kombinieren**

-   z.B. Pre- und post-exposure Messungen bei einem Experiment.

## `bind_rows()` {auto-animate="T"}

::: columns
::: {.column width="50%"}
x

[ID]{.square_darkgrey data-id="boxThree1"} [B]{.square_darkgrey data-id="boxThree2"} [C]{.square_darkgrey data-id="boxThree3"}

[a]{.square_lightgrey data-id="boxThree4"} [t]{.square_lightgrey data-id="boxThree5"} [1]{.square_lightgrey data-id="boxThree6"}

[b]{.square_lightgrey data-id="boxThree7"} [u]{.square_lightgrey data-id="boxThree8"} [2]{.square_lightgrey data-id="boxThree9"}
:::

::: {.column width="50%"}
y

[ID]{.square_darkblue data-id="boxThree13"} [B]{.square_darkblue data-id="boxThree14"} [D]{.square_darkblue data-id="boxThree15"}

[c]{.square_lightblue data-id="boxThree19"} [v]{.square_lightblue data-id="boxThree20"} [3]{.square_lightblue data-id="boxThree21"}

[d]{.square_lightblue data-id="boxThree22"} [w]{.square_lightblue data-id="boxThree23"} [4]{.square_lightblue data-id="boxThree24"}
:::
:::

## `bind_rows()` {auto-animate="T"}

x & y

::: columns
::: {.column width="50%" style="color: white;"}
\_ [ID]{.square_darkgrey data-id="boxThree1"} [B]{.square_darkgrey data-id="boxThree2"} [C]{.square_darkgrey data-id="boxThree3"}

\_ [a]{.square_lightgrey data-id="boxThree4"} [t]{.square_lightgrey data-id="boxThree5"} [1]{.square_lightgrey data-id="boxThree6"}

\_ [b]{.square_lightgrey data-id="boxThree7"} [u]{.square_lightgrey data-id="boxThree8"} [2]{.square_lightgrey data-id="boxThree9"}

\_ [c]{.square_lightblue data-id="boxThree19"} [v]{.square_lightblue data-id="boxThree20"} [3]{.square_lightblue data-id="boxThree21"}

\_ [d]{.square_lightblue data-id="boxThree22"} [w]{.square_lightblue data-id="boxThree23"} [4]{.square_lightblue data-id="boxThree24"}
:::

::: {.column width="50%"}
:::
:::

## "Komplexeres" zusammenf√ºgen

<div>

-   Neben "Anh√§ngen" gibt es "intelligentere*"* Varianten, Datens√§tze zusammenzuf√ºhren,

-   z.B. durch einen **gemeinsamen Schl√ºssel**

    -   = Variable, die F√§lle in einem Datensatz mit einem anderen verbindet

    -   Meist existiert daf√ºr eine ID-Variable

    -   z.B. f√ºr jede/n Teilnehmer\*in in jedem Datensatz.

-   M√∂glichkeiten der Verkn√ºpfung unterscheiden sich bez√ºglich des Umgangs mit unterschiedlichen Werten im gemeinsamen Schl√ºssel

-   **Varianten**:

    ::: incremental
    -   Left Join

    -   Right Join

    -   Inner Join

    -   Full Join
    :::

</div>

## √úbersicht

![Source: @db-0121](https://cdn.mindmajix.com/blog/images/db-01_2119.png)

## `left_join()` {auto-animate="T"}

::: columns
::: {.column width="auto"}
x

[ID]{.square_darkgrey data-id="1_box_1"} [B]{.square_darkgrey data-id="1_box_2"} [C]{.square_darkgrey data-id="1_box_3"}

[a]{.square_lightgrey data-id="1_box_4"} [t]{.square_lightgrey data-id="1_box_5"} [1]{.square_lightgrey data-id="1_box_6"}

[b]{.square_lightgrey data-id="1_box_7"} [u]{.square_lightgrey data-id="1_box_8"} [2]{.square_lightgrey data-id="1_box_9"}

[c]{.square_lightgrey data-id="1_box_10"} [v]{.square_lightgrey data-id="1_box_11"} [3]{.square_lightgrey data-id="1_box_12"}
:::

::: {.column width="40%"}
:::

::: {.column width="auto"}
y

[ID]{.square_darkblue data-id="1_box_13"} [B]{.square_darkblue data-id="1_box_14"} [D]{.square_darkblue data-id="1_box_15"}

[a]{.square_lightblue data-id="1_box_16"} [t]{.square_lightblue data-id="1_box_17"} [3]{.square_lightblue data-id="1_box_18"}

[b]{.square_lightblue data-id="1_box_19"} [u]{.square_lightblue data-id="1_box_20"} [2]{.square_lightblue data-id="1_box_21"}

[d]{.square_lightblue data-id="1_box_22"} [w]{.square_lightblue data-id="1_box_23"} [1]{.square_lightblue data-id="1_box_24"}
:::
:::

## `left_join()` {auto-animate="T"}

<div>

::: columns
::: {.column width="auto"}
x & y

[ID]{.square_darkgrey data-id="1_box_1"} [B]{.square_darkgrey data-id="1_box_2"} [C]{.square_darkgrey data-id="1_box_3"} [D]{.square_darkblue data-id="1_box_15"}

[a]{.square_lightblue data-id="1_box_16"} [t]{.square_lightgrey data-id="1_box_5"} [1]{.square_lightgrey data-id="1_box_6"} [3]{.square_lightblue data-id="1_box_18"}

[b]{.square_lightblue data-id="1_box_19"} [u]{.square_lightgrey data-id="1_box_8"} [2]{.square_lightgrey data-id="1_box_9"} [2]{.square_lightblue data-id="1_box_21"}

[c]{.square_lightgrey data-id="1_box_10"} [v]{.square_lightgrey data-id="1_box_11"} [3]{.square_lightgrey data-id="1_box_12"}
:::

::: {.column width="40%"}
:::
:::

</div>

## `left_join()` {auto-animate="T" auto-animate-unmatched="F"}

<div>

::: columns
::: {.column width="auto"}
x & y

[ID]{.square_darkgrey data-id="1_box_1"} [B]{.square_darkgrey data-id="1_box_2"} [C]{.square_darkgrey data-id="1_box_3"} [D]{.square_darkblue data-id="1_box_15"}

[a]{.square_lightblue data-id="1_box_16"} [t]{.square_lightgrey data-id="1_box_5"} [1]{.square_lightgrey data-id="1_box_6"} [3]{.square_lightblue data-id="1_box_18"}

[b]{.square_lightblue data-id="1_box_19"} [u]{.square_lightgrey data-id="1_box_8"} [2]{.square_lightgrey data-id="1_box_9"} [2]{.square_lightblue data-id="1_box_21"}

[c]{.square_lightgrey data-id="1_box_10"} [v]{.square_lightgrey data-id="1_box_11"} [3]{.square_lightgrey data-id="1_box_12"} [NA]{.square_white data-id=""}
:::

::: {.column width="40%"}
:::
:::

</div>

-   Erh√§lt alle einzigartigen F√§lle (ID) des linken/ersten Datensatzes

-   **Nicht** die einzigartigen F√§lle des rechten Datensatzes

-   Fehlende Variablen werden zu NAs

## `right_join()` {auto-animate="T"}

::: columns
::: {.column width="auto"}
x

[ID]{.square_darkgrey data-id="box_1"} [B]{.square_darkgrey data-id="box_2"} [C]{.square_darkgrey data-id="box_3"}

[a]{.square_lightgrey data-id="box_4"} [t]{.square_lightgrey data-id="box_5"} [1]{.square_lightgrey data-id="box_6"}

[b]{.square_lightgrey data-id="box_7"} [u]{.square_lightgrey data-id="box_8"} [2]{.square_lightgrey data-id="box_9"}

[c]{.square_lightgrey data-id="box_10"} [v]{.square_lightgrey data-id="box_11"} [3]{.square_lightgrey data-id="box_12"}
:::

::: {.column width="40%"}
:::

::: {.column width="auto"}
y

[ID]{.square_darkblue data-id="box_13"} [B]{.square_darkblue data-id="box_14"} [D]{.square_darkblue data-id="box_15"}

[a]{.square_lightblue data-id="box_16"} [t]{.square_lightblue data-id="box_17"} [3]{.square_lightblue data-id="box_18"}

[b]{.square_lightblue data-id="box_19"} [u]{.square_lightblue data-id="box_20"} [2]{.square_lightblue data-id="box_21"}

[d]{.square_lightblue data-id="box_22"} [w]{.square_lightblue data-id="box_23"} [1]{.square_lightblue data-id="box_24"}
:::
:::

## `right_join()` {auto-animate="T"}

::: columns
::: {.column width="40%"}
:::

::: {.column width="auto"}
x & y

[ID]{.square_darkblue data-id="box_13"} [B]{.square_darkblue data-id="box_14"} [C]{.square_darkgrey data-id="box_3"} [D]{.square_darkblue data-id="box_15"}

[a]{.square_lightgrey data-id="box_4"} [t]{.square_lightblue data-id="box_17"} [1]{.square_lightgrey data-id="box_6"} [3]{.square_lightblue data-id="box_18"}

[b]{.square_lightgrey data-id="box_7"} [u]{.square_lightblue data-id="box_20"} [2]{.square_lightgrey data-id="box_9"} [2]{.square_lightblue data-id="box_21"}

[d]{.square_lightblue data-id="box_22"} [w]{.square_lightblue data-id="box_23"} [NA]{.square_white data-id=""} [1]{.square_lightblue data-id="box_24"}
:::
:::

-   Identisch zu `left_join`, nur "rechts"

## `inner_join()` {auto-animate="T"}

::: columns
::: {.column width="auto"}
x

[ID]{.square_darkgrey data-id="boxTwo1"} [B]{.square_darkgrey data-id="boxTwo2"} [C]{.square_darkgrey data-id="boxTwo3"}

[a]{.square_lightgrey data-id="boxTwo4"} [t]{.square_lightgrey data-id="boxTwo5"} [1]{.square_lightgrey data-id="boxTwo6"}

[b]{.square_lightgrey data-id="boxTwo7"} [u]{.square_lightgrey data-id="boxTwo8"} [2]{.square_lightgrey data-id="boxTwo9"}

[c]{.square_lightgrey data-id="boxTwo10"} [v]{.square_lightgrey data-id="boxTwo11"} [3]{.square_lightgrey data-id="boxTwo12"}
:::

::: {.column width="40%"}
:::

::: {.column width="auto"}
y

[ID]{.square_darkblue data-id="boxTwo13"} [B]{.square_darkblue data-id="boxTwo14"} [D]{.square_darkblue data-id="boxTwo15"}

[a]{.square_lightblue data-id="boxTwo16"} [t]{.square_lightblue data-id="boxTwo17"} [3]{.square_lightblue data-id="boxTwo18"}

[b]{.square_lightblue data-id="boxTwo19"} [u]{.square_lightblue data-id="boxTwo20"} [2]{.square_lightblue data-id="boxTwo21"}

[d]{.square_lightblue data-id="boxTwo22"} [w]{.square_lightblue data-id="boxTwo23"} [1]{.square_lightblue data-id="boxTwo24"}
:::
:::

## `inner_join()` {auto-animate="T"}

::: columns
::: {.column width="auto"}
x & y

[ID]{.square_darkgrey data-id="boxTwo1"} [B]{.square_darkgrey data-id="boxTwo2"} [C]{.square_darkgrey data-id="boxTwo3"} [D]{.square_darkblue data-id="boxTwo15"}

[a]{.square_lightblue data-id="boxTwo16"} [t]{.square_lightgrey data-id="boxTwo5"} [1]{.square_lightgrey data-id="boxTwo6"} [3]{.square_lightblue data-id="boxTwo18"}

[b]{.square_lightblue data-id="boxTwo19"} [u]{.square_lightgrey data-id="boxTwo8"} [2]{.square_lightgrey data-id="boxTwo9"} [2]{.square_lightblue data-id="boxTwo21"}
:::

::: {.column width="40%"}
:::

::: {.column width="auto"}
:::
:::

-   Es werden nur IDs behalten, die in beiden Datens√§tzen existieren

## `full_join()` {auto-animate="T"}

::: columns
::: {.column width="auto"}
x

[ID]{.square_darkgrey data-id="box_1"} [B]{.square_darkgrey data-id="box_2"} [C]{.square_darkgrey data-id="box_3"}

[a]{.square_lightgrey data-id="box_4"} [t]{.square_lightgrey data-id="box_5"} [1]{.square_lightgrey data-id="box_6"}

[b]{.square_lightgrey data-id="box_7"} [u]{.square_lightgrey data-id="box_8"} [2]{.square_lightgrey data-id="box_9"}

[c]{.square_lightgrey data-id="box_10"} [v]{.square_lightgrey data-id="box_11"} [3]{.square_lightgrey data-id="box_12"}

<br>

<br>

<br>
:::

::: {.column width="40%"}
:::

::: {.column width="auto"}
y

[ID]{.square_darkblue data-id="box_13"} [B]{.square_darkblue data-id="box_14"} [D]{.square_darkblue data-id="box_15"}

[a]{.square_lightblue data-id="box_16"} [t]{.square_lightblue data-id="box_17"} [3]{.square_lightblue data-id="box_18"}

[b]{.square_lightblue data-id="box_19"} [u]{.square_lightblue data-id="box_20"} [2]{.square_lightblue data-id="box_21"}

[d]{.square_lightblue data-id="box_22"} [w]{.square_lightblue data-id="box_23"} [1]{.square_lightblue data-id="box_24"}
:::
:::

## `full_join()` {auto-animate="T"}

::: columns
::: {.column width="40%"}
x & y

[ID]{.square_darkgrey data-id="box_1"} [B]{.square_darkgrey data-id="box_2"} [C]{.square_darkgrey data-id="box_3"} [D]{.square_darkblue data-id="box_15"}

[a]{.square_lightblue data-id="box_16"} [t]{.square_lightgrey data-id="box_5"} [1]{.square_lightgrey data-id="box_6"} [3]{.square_lightblue data-id="box_18"}

[b]{.square_lightblue data-id="box_19"} [u]{.square_lightgrey data-id="box_8"} [2]{.square_lightgrey data-id="box_9"} [2]{.square_lightblue data-id="box_21"}

[c]{.square_lightgrey data-id="box_10"} [v]{.square_lightgrey data-id="box_11"} [3]{.square_lightgrey data-id="box_12"} [NA]{.square_white data-id=""}

[d]{.square_lightblue data-id="box_22"} [w]{.square_lightblue data-id="box_23"} [NA]{.square_white data-id=""} [1]{.square_lightblue data-id="box_24"}
:::

::: {.column width="auto"}
:::
:::

-   **Alle** Werte und Reihen werden erhalten

# Aufgabe 1

1.  Lesen Sie die zwei Datens√§tze aus dem Pretest aus dem Ordner `data` ein:

    -   `Momentary_Disco!+NO+LOGGING_20221020T113348+0200.xlsx`

    -   `momentary_disco_WITH_logging_20221020T113642+0200.xlsx`

    -   a\) Welche Funktion nutzen Sie zum einlesen?

2.  Vereinheitlichen Sie die Variablennamen mit `janitor::clean_names()`

3.  Verbinden Sie die beiden Datens√§tze

    -   a\) Welche Funktion nutzen Sie und wieso?

4.  Untersuchen Sie Variablen der Datens√§tze mit `glimpse()` mit `sjmisc::frq()`

    -   a\) Was stellen Sie fest?

# L√∂sung 1

**‚ö†Ô∏è Erst nach der Bearbeitung weiterklicken! ‚ö†Ô∏è**

## Einlesen

```{r read}
# Importing data from the version **without** logging
d_log_f = read_excel("../../pretest/data/Momentary_Disco!+NO+LOGGING_20221020T113348+0200.xlsx")

# Importing data from the version **with** logging
d_log_t = read_excel("../../pretest/data/momentary_disco_WITH_logging_20221020T113642+0200.xlsx")

colnames(d_log_t)
```

## `clean_names()`

::: columns
::: {.column width="50%"}
```{r}
colnames(
  d_log_t
  )
```
:::

::: {.column width="50%"}
```{r}
d_log_t_c = d_log_t %>%
  clean_names() # tidy names
colnames(d_log_t_c)
```
:::
:::

## Adding rows

```{r}
data_both = rbind(d_log_f, d_log_t)
```

::: columns
::: {.column width="50%"}
```{r}
summary(d_log_f)
```
:::

::: {.column width="50%"}
```{r}
summary(data)
```
:::
:::

-   Warum habe ich hier `rbind()` verwendet?

## Taking a `glimpse()`

```{r}
#| eval: false
d_log_t %>% glimpse()

sjmisc::frq(d_log_t$form)
```

# Datenbereinigung

**Von Rohdaten zu konsistenten Daten**

üëÄ missing üíØ extremwerte üìè straightlining

## Stufen der Datenqualit√§t

::: columns
::: {.column width="66%"}
-   Ziel der Datenbereingiung ist die Steigerung der Datenqualit√§t

-   Der Prozess umfasst mehrere Schritte

-   Teilweise mehrfach wiederholt

-   Gelingt nur durch eine aktive Auseinandersetzung mit den Daten
:::

::: {.column width="33%"}
![@dejonge](../../images/02_pre_processing_chain.jpg)
:::
:::

## Typische Strategie[^2]

[^2]: Nach @ronaldk.pearson2018 p. 81

1.  Bewertung allgemeiner Merkmale des Datensatzes, z. B.:

    -   Wie viele F√§lle sind enthalten? Wie viele Variablen?

    -   Wie lauten die Variablennamen? Sind sie sinnvoll?

    -   Welchen Typ hat jede Variable: numerisch, kategorisch, logisch

    -   Wie viele eindeutige Werte hat jede Variable?

    -   Welcher Wert tritt am h√§ufigsten auf, und wie oft kommt er vor?

    -   Gibt es fehlende Werte? Wenn ja, wie h√§ufig ist dies der Fall?

2.  Untersuchung deskriptiver Statistiken f√ºr jede Variable;

3.  Explorative Visualisierung (mind. f√ºr besonders relevante Variablen)

4.  Suche nach Anomalien in den Daten (mind. f√ºr besonders relevante Variablen)

5.  Untersuchung der Beziehungen zwischen Schl√ºsselvariablen mit Hilfe von Scatterplots/Boxplots/Mosaic-Plots;

6.  Dokumentation des Vorgehens und der Ergebnisse (z.B. mit .qmd-Dokument). Dient als Grundlage f√ºr die anschlie√üende Analyse und Erl√§uterung der Ergebnisse.

## Umgang mit fehlenden Werten

-   Variierende Gr√ºnde f√ºr fehlende Werte (Ausf√ºllverhalten, Studiendesign etc.)

-   K√∂nnen mit verschiedenen Problemem verbunden sein (Verringerung statistischer Aussagekraft, Verzerrung von Sch√§tzungen etc.)

**Fokus im Kontext dieser Sitzung:**

-   √úberpr√ºfung der Join/Merge-Prozedur

-   Plausibilit√§tspr√ºfung (Kontrolle der fehlenden Werte f√ºr Variablen und F√§lle)

-   Vielzahl an Paketen und Funktionen:

    -   `visdat`

    -   `naniar`

    -   `dlookr`(::diagnose)

    -   `DataExplorer`

    -   ...

## Visualisierung fehlender Werte mit `visdat`

```{r}
#example with a subset of variables/observations
data[c(50:70),c(1:51)] %>% vis_miss() + 
  theme(axis.text.x = element_text(angle = 90, size = 9))


```

## **F√§lle mit hohem Anteil an fehlenden Werten**

-   `miss_case_summary` (bzw. `miss_var_summary`); F√§lle (Variablen ) mit einem hohen Anteil Missing Values identifizieren

```{r}
data %>%
  filter(Form == "a Situational Survey"  | Form == "b End of Day") %>%
  group_by(id) %>% 
  miss_case_summary() %>% 
  summarise_all(mean)
```

-   Dann mit der filter-Funktion (bzw. select-Funktion bei Variablen) f√ºr die weitere Analyse ausschlie√übar

```{r}
df_excluded = data %>% 
  filter(id != "yl_533")
```

## Anomalien in Daten {style=".incremental"}

::: columns
::: {.column .incremental width="60%"}
-   Typischerweise besonders (uni- und multivariate) **Ausrei√üer** und **Extremwerte** im Fokus

-   Zus√§tzlich Pr√ºfen von

    -   Besonderheiten, z.B. auff√§llige Antwortmuster

    -   einzelne Parameter im Hinblick auf inhaltliche Kriterien, z.B. Ausf√ºlldauer, Gewissenhaftigkeit

-   Im Fokus: **Straightlining**

    -   = (nahezu) identische Antworten in einer Reihe von Fragenbatterien mit denselben Antwortkategorien
:::

::: {.column width="40%"}
![[Tumisu on Pixabay](https://pixabay.com/illustrations/checklist-list-check-mark-business-1919328/)](https://cdn.pixabay.com/photo/2016/12/19/23/11/checklist-1919328_960_720.png)
:::
:::

## Identifikation von "Straightlining"

::: columns
::: {.column width="50%"}
Verschiedene Ans√§tze

-   Anteil der befragten Personen, die nur eine einzige Antwortkategorie verwenden

-   Mittelwert der Wurzel der aboluten Differenzen zwischen allen Itempaaren innerhalb einer Batterie

-   Anteil der maximalen Anzahl identischer Ratings innerhalb einer Batterie

-   Standardabweichung oder **Varianz des Ratings f√ºr jede befragte Person**
:::

::: {.column width="50%"}
```{r}
var = sosci_pre_survey %>%
  replace(is.na(.), 0) %>% 
  rowwise() %>%
  mutate(
    # here example for only a few variables
    var_disco_level = var(c_across(disco_level_w_1:disco_level_w_6)), 
    var_disco_tech = var(c_across(disco_tech_w_1:disco_tech_w_6)),
    var_mindfulness = var(c_across(mindfulness_01:mindfulness_05)),
  ) %>%
  mutate(
    id = id,
    across(contains("var_"), round, 2)
    )
```
:::
:::

## Identifikation von "Straighlining": Varianz

::: columns
::: {.column width="40%"}
### Code

```{r}
plot = var %>%
  select(id, contains("var_")) %>%
  mutate(across(contains("var_"),
                ~ sjmisc::rec(.,rec = "0=1;else=0"))) %>%
  mutate(var_sum =
           rowSums(across(contains("var_")))) %>%
  sjPlot::plot_frq(var_sum) +
  labs(
    title = "Identifying Straightlining",
    x = "Number of indices without variance",
    y = "Number of cases") +
  theme_pubr()
```
:::

::: {.column width="60%"}
### Plot

```{r}
plot
```

:::
:::

# Aufgabe 2

1.  Lesen Sie den Pretest-Vorbefragungs-Datensatz `data_abschalten_2022-10-20_18-11.xlsx` ein
2.  √úberpr√ºfen Sie die Anzahl der Missing Values **pro Variable** mit Hilfe der Funktion `naniar::miss_var_summary`
3.  Identifizieren Sie Straightlining (f√ºr ausgew√§hlte Variablen)
4.  Verbinden Sie den Pretest-Vorbefragungs-Datensatz mit den bereits eingelesenen situationsbezogenen Frageb√∂gen (Tip auf der n√§chsten Seite beachten)

## Tip: Logging-Varianten-Aufarbeitung

Die zwei Varianten (mit und ohne Logging) beinhalten zus√§tzlichen Aufwand bei der Aufbereitung. Sie k√∂nnen den folgenden Code nutzen, um die IDs zu erstellen:

```{r}
# note: 9 needs to be added because 1-9 were reserved for the technical pretest
# adding 9 for both
sosci_pre_survey = sosci_pre_survey %>% 
  mutate(
    movi_id_nl = UR01+9, #1 in the urn corresponds to id no. 10
    movi_id_yl = UR02+9  #1 in the urn corresponds to id no. 10
  ) %>% 
  select(movi_id_nl, movi_id_yl, everything())

#creating id variable for non-logging version
sosci_pre_survey_nl = sosci_pre_survey %>% 
  filter(!is.na(movi_id_nl)) %>% 
  mutate(id = paste0("nl_", movi_id_nl)) %>%
  select(id, everything())

#creating id variable for logging version
sosci_pre_survey_yl = sosci_pre_survey %>% 
  filter(!is.na(movi_id_yl)) %>% 
  mutate(id = paste0("yl_", movi_id_yl)) %>%
  select(id, everything())

sosci_pre_survey = rbind(sosci_pre_survey_nl, sosci_pre_survey_yl) #joining both versions
```

# L√∂sung 2

**‚ö†Ô∏è Erst nach der Bearbeitung weiterklicken! ‚ö†Ô∏è**

## Datensatz einlesen

Wie bisher:

```{r}
#| eval: false
sosci_pre_survey = read_excel("../../pretest/data/data_abschalten_2022-10-20_18-11.xlsx", col_types = "guess")

#converting one double to string
sosci_pre_survey = sosci_pre_survey %>% mutate(FI04_01 = toString(FI04_01))
```

## Missing values pr√ºfen

```{r}
miss_var_summary(sosci_pre_survey)
```

## Straightlining pr√ºfen

::: columns
::: {.column width="50%"}
```{r}
# creating variance variables
var = sosci_pre_survey %>%
  replace(is.na(.), 0) %>% 
  rowwise() %>%
  mutate(
    # here example for only a few variables
    var_disco_level = var(c_across(disco_level_w_1:disco_level_w_6)), 
    var_disco_tech = var(c_across(disco_tech_w_1:disco_tech_w_6)),
    var_mindfulness = var(c_across(mindfulness_01:mindfulness_05)),
    var_availability = var(c_across(availability_preference_01:availability_preference_04)),
    var_disco_context = var(c_across(disco_context_1:disco_context_11)),
    var_fomo = var(c_across(fomo_01:fomo_10)),
    # ...
    # ...
    # ...
  ) %>%
  mutate(
    id = id,
    across(contains("var_"), round, 2)
    )
```

```{r}
# creating plot
plot = var %>%
  select(id, contains("var_")) %>%
  mutate(across(contains("var_"),
                ~ sjmisc::rec(.,rec = "0=1;else=0"))) %>%
  mutate(var_sum =
           rowSums(across(contains("var_")))) %>%
  sjPlot::plot_frq(var_sum) +
  labs(
    title = "Identifying Straightlining",
    x = "Number of indices without variance",
    y = "Number of cases") +
  theme_pubr()
```
:::

::: {.column width="50%"}
```{r}
#| echo: false
plot
```
:::
:::

## Alle Datens√§tze zusammenf√ºgen

```{r}
data_long = merge(data, sosci_pre_survey, by = "id")

data_long = data_long %>%
  clean_names
```

# Bonus

**Falls noch Zeit ist**

## Datenimport mit readr

-   Empfehlung: readr-Paket

    -   Standardpaket, wenn "Import Dataset..."-Option im File-Pane genutzt wird (und es sich um "einfache" tabellarische Daten handelt)

    -   Erm√∂glicht Definition und Erkennung zus√§tzliche Argumente (z.B zur Spezifikation des Variablentyps bzw. -class)

    ```{r}
    #| eval: false
    df = read_delim(
      file = "example.csv",
      delim = "\t",
      escape_double = F,
      trim_ws = T
    )
    ```

## `dplyr` vs. base R zusammenf√ºgen

::: columns
::: {.column width="50%"}
### Base R

```{r}
#| eval: false
merge(
x = dataframe_1,  y = dataframe_2,
by = "key",
all = F)
```

-   Zus√§tzliche Argumente f√ºr:
    -   left join: `all.x = T`

    -   right_Join: `all.y = T`

    -   full_join: `all = F`
:::

::: {.column width="50%"}
### dplyr

```{r}
#| eval: false
inner_join(
x = dataframe_1,  y = dataframe_2,
by = "key")
```

-   dplyr bietet eine Funktion f√ºr jede Art von Verkn√ºpfung:

    -   `right_join()`

    -   `left_join()`

    -   `full_join()`
    

:::
:::

# Literatur
